{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Using {}'.format(device))\n",
    "torch.device(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training variables\n",
    "\n",
    "imgTransformSize = 224\n",
    "#range of degrees +- to rotate\n",
    "imgTransformRngRot = 5\n",
    "\n",
    "epochs = 25\n",
    "\n",
    "modelLearnRate = 0.05\n",
    "modelMomentum= 0.5\n",
    "modelWeightDecay= 0.003\n",
    "\n",
    "\n",
    "train_dataset_path = './datasets/FoodTrain1'\n",
    "valid_dataset_path = './datasets/FoodValidate1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(scale=(0.6, 1.0), size=(imgTransformSize,imgTransformSize)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(imgTransformRngRot),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "valid_transforms = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(size=(imgTransformSize,imgTransformSize)),\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torchvision.datasets.ImageFolder(root = train_dataset_path, transform = train_transforms)\n",
    "valid_dataset = torchvision.datasets.ImageFolder(root = valid_dataset_path, transform = valid_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_transformed_images(dataset):\n",
    "    loader = torch.utils.data.DataLoader(dataset, batch_size = 6, shuffle=True)\n",
    "    batch = next(iter(loader))\n",
    "    images, labels = batch\n",
    "    \n",
    "    grid = torchvision.utils.make_grid(images, nrow=3)\n",
    "    plt.figure(figsize=(11,11))\n",
    "    plt.imshow(np.transpose(grid,(1,2,0)))\n",
    "    print('labels: ', labels)\n",
    "\n",
    "#show_transformed_images(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size = 32, shuffle = True)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size = 32, shuffle = False)\n",
    "\n",
    "train_losses, valid_losses = [], []\n",
    "train_accs, valid_accs = [], []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "resnet18_model = models.resnet18(weights = models.ResNet18_Weights.DEFAULT)\n",
    "num_features = resnet18_model.fc.in_features\n",
    "num_object_categories = 40 \n",
    "resnet18_model.fc = nn.Linear(num_features, num_object_categories)\n",
    "resnet18_model = resnet18_model.to(device)\n",
    "\n",
    "\n",
    "resnet50_model = models.resnet50(weights = models.ResNet50_Weights.IMAGENET1K_V2)\n",
    "num_features = resnet50_model.fc.in_features\n",
    "num_object_categories = 40 \n",
    "resnet50_model.fc = nn.Linear(num_features, num_object_categories)\n",
    "resnet50_model = resnet50_model.to(device)\n",
    "\n",
    "\n",
    "#The model we're actually using\n",
    "usedModel = resnet50_model\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "now = datetime.now()\n",
    "checkpointName = now.strftime(\"%y%m%d%H%M\")\n",
    "\n",
    "if (usedModel == resnet50_model):\n",
    "    checkpointName = 'resnet50_'+checkpointName\n",
    "else:\n",
    "    checkpointName = 'resnet18_'+checkpointName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "optimiser = optim.SGD(usedModel.parameters(), lr=modelLearnRate, momentum=modelMomentum, weight_decay=modelWeightDecay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(model, epoch, optimiser, best_acc):\n",
    "    state = {\n",
    "        'epoch': epoch+1,\n",
    "        'model': model.state_dict(),\n",
    "        'best_accuracy': best_acc,\n",
    "        'optimiser' : optimiser.state_dict(),\n",
    "        'comments':'learning rate: {:.2f} momentum: {:.2f} Weight Decay: {:.5f}'.format(modelLearnRate, modelMomentum, modelWeightDecay)\n",
    "    }\n",
    "\n",
    "    torch.save(state, checkpointName+'.pth.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_network(model, train_loader, valid_loader, criterion, optimiser, n_epochs):\n",
    "    \n",
    "    best_acc = 0\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        #print(\"Epoch number %d (epoch + 1)\")\n",
    "        model.train()\n",
    "        epoch_loss, epoch_accuracy = 0, 0\n",
    "        epoch_valid_accuracy, epoch_valid_loss = 0, 0\n",
    "        totalImg = 0\n",
    "        running_total = 0\n",
    "\n",
    "        for data in train_loader:\n",
    "            images, labels = data\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            totalImg += labels.size(0)\n",
    "\n",
    "            optimiser.zero_grad()\n",
    "\n",
    "            outputs = model(images)\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "\n",
    "            optimiser.step()\n",
    "\n",
    "            acc = ((outputs.argmax(dim=1) == labels).float().mean())\n",
    "\n",
    "            running_total += (outputs.argmax(dim=1) == labels).sum().item()\n",
    "\n",
    "            epoch_accuracy += acc/len(train_loader)\n",
    "            epoch_loss += loss/len(train_loader)\n",
    "\n",
    "        print('Epoch: {}, train accuracy: {:.2f}%, train loss: {:.4f}'.format(epoch+1, epoch_accuracy*100, epoch_loss), end=\" | \")\n",
    "        train_losses.append(epoch_loss.item())\n",
    "        train_accs.append(epoch_accuracy.item())\n",
    "\n",
    "        #print(\"     -training set got %d out of %d images (%.3f%%)\" % (running_total, totalImg, epoch_accuracy*100))\n",
    "        model.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "\n",
    "            for data in valid_loader:\n",
    "                images, labels = data\n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                valid_output = model(images)\n",
    "                valid_loss = loss_fn(valid_output, labels)\n",
    "\n",
    "                acc = ((valid_output.argmax(dim=1) == labels).float().mean())\n",
    "                epoch_valid_accuracy += acc/len(valid_loader)\n",
    "                epoch_valid_loss += valid_loss/len(valid_loader) \n",
    "                \n",
    "        print('Epoch: {}, validation accuracy: {:.2f}%, valid loss: {:.4f}'.format(epoch+1, epoch_valid_accuracy*100, epoch_valid_loss))\n",
    "        valid_losses.append(epoch_valid_loss.item())\n",
    "        valid_losses.append(epoch_valid_accuracy.item())\n",
    "\n",
    "        if best_acc <= epoch_valid_accuracy:\n",
    "            best_acc = epoch_valid_accuracy\n",
    "            save_checkpoint(model, epoch, optimiser, best_acc)\n",
    "\n",
    "    print(\"training complete\")\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, train accuracy: 9.03%, train loss: 3.6586 | Epoch: 1, validation accuracy: 20.31%, valid loss: 3.5219\n",
      "Epoch: 2, train accuracy: 32.81%, train loss: 3.2143 | Epoch: 2, validation accuracy: 23.44%, valid loss: 3.3999\n",
      "Epoch: 3, train accuracy: 53.30%, train loss: 2.5710 | Epoch: 3, validation accuracy: 28.12%, valid loss: 3.1864\n",
      "Epoch: 4, train accuracy: 75.35%, train loss: 1.6645 | Epoch: 4, validation accuracy: 35.94%, valid loss: 2.7651\n",
      "Epoch: 5, train accuracy: 72.83%, train loss: 1.1921 | Epoch: 5, validation accuracy: 40.62%, valid loss: 2.4733\n",
      "Epoch: 6, train accuracy: 92.97%, train loss: 0.6674 | Epoch: 6, validation accuracy: 39.06%, valid loss: 2.3094\n",
      "Epoch: 7, train accuracy: 98.44%, train loss: 0.3840 | Epoch: 7, validation accuracy: 46.88%, valid loss: 1.9499\n",
      "Epoch: 8, train accuracy: 97.22%, train loss: 0.2711 | Epoch: 8, validation accuracy: 50.00%, valid loss: 1.8822\n",
      "Epoch: 9, train accuracy: 99.22%, train loss: 0.2329 | Epoch: 9, validation accuracy: 59.38%, valid loss: 1.6278\n",
      "Epoch: 10, train accuracy: 100.00%, train loss: 0.1285 | Epoch: 10, validation accuracy: 51.56%, valid loss: 1.6572\n",
      "Epoch: 11, train accuracy: 100.00%, train loss: 0.1660 | Epoch: 11, validation accuracy: 60.94%, valid loss: 1.8577\n",
      "Epoch: 12, train accuracy: 100.00%, train loss: 0.1384 | Epoch: 12, validation accuracy: 60.94%, valid loss: 1.6885\n",
      "Epoch: 13, train accuracy: 100.00%, train loss: 0.1124 | Epoch: 13, validation accuracy: 56.25%, valid loss: 1.6499\n",
      "Epoch: 14, train accuracy: 100.00%, train loss: 0.0802 | Epoch: 14, validation accuracy: 57.81%, valid loss: 1.5226\n",
      "Epoch: 15, train accuracy: 100.00%, train loss: 0.0649 | Epoch: 15, validation accuracy: 51.56%, valid loss: 1.7746\n",
      "Epoch: 16, train accuracy: 100.00%, train loss: 0.0857 | Epoch: 16, validation accuracy: 60.94%, valid loss: 1.5812\n",
      "Epoch: 17, train accuracy: 100.00%, train loss: 0.0401 | Epoch: 17, validation accuracy: 64.06%, valid loss: 1.6135\n",
      "Epoch: 18, train accuracy: 100.00%, train loss: 0.0541 | Epoch: 18, validation accuracy: 65.62%, valid loss: 1.4191\n",
      "Epoch: 19, train accuracy: 100.00%, train loss: 0.0252 | Epoch: 19, validation accuracy: 53.12%, valid loss: 1.5282\n",
      "Epoch: 20, train accuracy: 100.00%, train loss: 0.0573 | Epoch: 20, validation accuracy: 60.94%, valid loss: 1.3702\n",
      "Epoch: 21, train accuracy: 100.00%, train loss: 0.0406 | Epoch: 21, validation accuracy: 67.19%, valid loss: 1.3249\n",
      "Epoch: 22, train accuracy: 100.00%, train loss: 0.0306 | Epoch: 22, validation accuracy: 68.75%, valid loss: 1.2089\n",
      "Epoch: 23, train accuracy: 100.00%, train loss: 0.0272 | Epoch: 23, validation accuracy: 67.19%, valid loss: 1.5763\n",
      "Epoch: 24, train accuracy: 100.00%, train loss: 0.1061 | Epoch: 24, validation accuracy: 60.94%, valid loss: 1.5038\n",
      "Epoch: 25, train accuracy: 100.00%, train loss: 0.0433 | Epoch: 25, validation accuracy: 62.50%, valid loss: 1.6003\n",
      "Epoch: 26, train accuracy: 97.22%, train loss: 0.0599 | Epoch: 26, validation accuracy: 60.94%, valid loss: 1.4705\n",
      "Epoch: 27, train accuracy: 100.00%, train loss: 0.0192 | Epoch: 27, validation accuracy: 64.06%, valid loss: 1.3430\n",
      "Epoch: 28, train accuracy: 100.00%, train loss: 0.0094 | Epoch: 28, validation accuracy: 64.06%, valid loss: 1.5225\n",
      "Epoch: 29, train accuracy: 100.00%, train loss: 0.0256 | Epoch: 29, validation accuracy: 68.75%, valid loss: 1.2653\n",
      "Epoch: 30, train accuracy: 100.00%, train loss: 0.0732 | Epoch: 30, validation accuracy: 56.25%, valid loss: 1.6019\n",
      "Epoch: 31, train accuracy: 100.00%, train loss: 0.0141 | Epoch: 31, validation accuracy: 59.38%, valid loss: 1.5700\n",
      "Epoch: 32, train accuracy: 100.00%, train loss: 0.0121 | Epoch: 32, validation accuracy: 64.06%, valid loss: 1.3540\n",
      "Epoch: 33, train accuracy: 100.00%, train loss: 0.0135 | Epoch: 33, validation accuracy: 60.94%, valid loss: 1.5047\n",
      "Epoch: 34, train accuracy: 100.00%, train loss: 0.0191 | Epoch: 34, validation accuracy: 48.44%, valid loss: 1.6360\n",
      "Epoch: 35, train accuracy: 100.00%, train loss: 0.0235 | Epoch: 35, validation accuracy: 73.44%, valid loss: 1.1476\n",
      "Epoch: 36, train accuracy: 100.00%, train loss: 0.0089 | Epoch: 36, validation accuracy: 59.38%, valid loss: 1.4270\n",
      "Epoch: 37, train accuracy: 100.00%, train loss: 0.0204 | Epoch: 37, validation accuracy: 65.62%, valid loss: 1.3940\n",
      "Epoch: 38, train accuracy: 97.22%, train loss: 0.0717 | Epoch: 38, validation accuracy: 64.06%, valid loss: 1.4979\n",
      "Epoch: 39, train accuracy: 100.00%, train loss: 0.0087 | Epoch: 39, validation accuracy: 59.38%, valid loss: 1.6619\n",
      "Epoch: 40, train accuracy: 100.00%, train loss: 0.0333 | Epoch: 40, validation accuracy: 62.50%, valid loss: 1.5207\n",
      "Epoch: 41, train accuracy: 100.00%, train loss: 0.0200 | Epoch: 41, validation accuracy: 51.56%, valid loss: 1.7025\n",
      "Epoch: 42, train accuracy: 100.00%, train loss: 0.0262 | Epoch: 42, validation accuracy: 65.62%, valid loss: 1.4279\n",
      "Epoch: 43, train accuracy: 100.00%, train loss: 0.0079 | Epoch: 43, validation accuracy: 68.75%, valid loss: 1.2862\n",
      "Epoch: 44, train accuracy: 100.00%, train loss: 0.0057 | Epoch: 44, validation accuracy: 60.94%, valid loss: 1.3781\n",
      "Epoch: 45, train accuracy: 100.00%, train loss: 0.0159 | Epoch: 45, validation accuracy: 62.50%, valid loss: 1.4139\n",
      "Epoch: 46, train accuracy: 100.00%, train loss: 0.0128 | Epoch: 46, validation accuracy: 53.12%, valid loss: 1.6302\n",
      "Epoch: 47, train accuracy: 100.00%, train loss: 0.0172 | Epoch: 47, validation accuracy: 71.88%, valid loss: 1.2983\n",
      "Epoch: 48, train accuracy: 100.00%, train loss: 0.0085 | Epoch: 48, validation accuracy: 65.62%, valid loss: 1.3277\n",
      "Epoch: 49, train accuracy: 100.00%, train loss: 0.0205 | Epoch: 49, validation accuracy: 67.19%, valid loss: 1.3437\n",
      "Epoch: 50, train accuracy: 100.00%, train loss: 0.0043 | Epoch: 50, validation accuracy: 60.94%, valid loss: 1.3355\n",
      "Epoch: 51, train accuracy: 100.00%, train loss: 0.0176 | Epoch: 51, validation accuracy: 65.62%, valid loss: 1.3150\n",
      "Epoch: 52, train accuracy: 100.00%, train loss: 0.0058 | Epoch: 52, validation accuracy: 68.75%, valid loss: 1.2663\n",
      "Epoch: 53, train accuracy: 100.00%, train loss: 0.0327 | Epoch: 53, validation accuracy: 60.94%, valid loss: 1.3832\n",
      "Epoch: 54, train accuracy: 100.00%, train loss: 0.0099 | Epoch: 54, validation accuracy: 57.81%, valid loss: 1.5599\n",
      "Epoch: 55, train accuracy: 99.22%, train loss: 0.0277 | Epoch: 55, validation accuracy: 65.62%, valid loss: 1.5377\n",
      "Epoch: 56, train accuracy: 100.00%, train loss: 0.0136 | Epoch: 56, validation accuracy: 71.88%, valid loss: 1.2822\n",
      "Epoch: 57, train accuracy: 100.00%, train loss: 0.0168 | Epoch: 57, validation accuracy: 62.50%, valid loss: 1.2446\n",
      "Epoch: 58, train accuracy: 100.00%, train loss: 0.0141 | Epoch: 58, validation accuracy: 59.38%, valid loss: 1.3307\n",
      "Epoch: 59, train accuracy: 100.00%, train loss: 0.0211 | Epoch: 59, validation accuracy: 75.00%, valid loss: 1.2011\n",
      "Epoch: 60, train accuracy: 100.00%, train loss: 0.0157 | Epoch: 60, validation accuracy: 56.25%, valid loss: 1.4652\n",
      "Epoch: 61, train accuracy: 100.00%, train loss: 0.0043 | Epoch: 61, validation accuracy: 70.31%, valid loss: 1.4230\n",
      "Epoch: 62, train accuracy: 100.00%, train loss: 0.0149 | Epoch: 62, validation accuracy: 59.38%, valid loss: 1.4763\n",
      "Epoch: 63, train accuracy: 100.00%, train loss: 0.0124 | Epoch: 63, validation accuracy: 51.56%, valid loss: 1.5886\n",
      "Epoch: 64, train accuracy: 100.00%, train loss: 0.0046 | Epoch: 64, validation accuracy: 70.31%, valid loss: 1.2739\n",
      "Epoch: 65, train accuracy: 100.00%, train loss: 0.0180 | Epoch: 65, validation accuracy: 65.62%, valid loss: 1.3009\n",
      "Epoch: 66, train accuracy: 97.22%, train loss: 0.1163 | Epoch: 66, validation accuracy: 65.62%, valid loss: 1.4005\n",
      "Epoch: 67, train accuracy: 98.44%, train loss: 0.0722 | Epoch: 67, validation accuracy: 64.06%, valid loss: 1.6300\n",
      "Epoch: 68, train accuracy: 99.22%, train loss: 0.0166 | Epoch: 68, validation accuracy: 64.06%, valid loss: 1.4993\n",
      "Epoch: 69, train accuracy: 100.00%, train loss: 0.0063 | Epoch: 69, validation accuracy: 62.50%, valid loss: 1.4319\n",
      "Epoch: 70, train accuracy: 100.00%, train loss: 0.0122 | Epoch: 70, validation accuracy: 65.62%, valid loss: 1.4582\n",
      "Epoch: 71, train accuracy: 100.00%, train loss: 0.0449 | Epoch: 71, validation accuracy: 64.06%, valid loss: 1.3190\n",
      "Epoch: 72, train accuracy: 100.00%, train loss: 0.0051 | Epoch: 72, validation accuracy: 65.62%, valid loss: 1.5453\n",
      "Epoch: 73, train accuracy: 100.00%, train loss: 0.0165 | Epoch: 73, validation accuracy: 64.06%, valid loss: 1.4172\n",
      "Epoch: 74, train accuracy: 100.00%, train loss: 0.0091 | Epoch: 74, validation accuracy: 62.50%, valid loss: 1.3078\n",
      "Epoch: 75, train accuracy: 100.00%, train loss: 0.0218 | Epoch: 75, validation accuracy: 62.50%, valid loss: 1.2697\n",
      "Epoch: 76, train accuracy: 100.00%, train loss: 0.0041 | Epoch: 76, validation accuracy: 60.94%, valid loss: 1.4562\n",
      "Epoch: 77, train accuracy: 100.00%, train loss: 0.0045 | Epoch: 77, validation accuracy: 65.62%, valid loss: 1.3235\n",
      "Epoch: 78, train accuracy: 100.00%, train loss: 0.0043 | Epoch: 78, validation accuracy: 64.06%, valid loss: 1.4247\n",
      "Epoch: 79, train accuracy: 100.00%, train loss: 0.0052 | Epoch: 79, validation accuracy: 65.62%, valid loss: 1.2836\n",
      "Epoch: 80, train accuracy: 100.00%, train loss: 0.0053 | Epoch: 80, validation accuracy: 48.44%, valid loss: 1.7154\n",
      "Epoch: 81, train accuracy: 100.00%, train loss: 0.0091 | Epoch: 81, validation accuracy: 62.50%, valid loss: 1.2081\n",
      "Epoch: 82, train accuracy: 100.00%, train loss: 0.0110 | Epoch: 82, validation accuracy: 51.56%, valid loss: 1.7106\n",
      "Epoch: 83, train accuracy: 100.00%, train loss: 0.0122 | Epoch: 83, validation accuracy: 64.06%, valid loss: 1.3745\n",
      "Epoch: 84, train accuracy: 100.00%, train loss: 0.0044 | Epoch: 84, validation accuracy: 60.94%, valid loss: 1.3610\n",
      "Epoch: 85, train accuracy: 100.00%, train loss: 0.0080 | Epoch: 85, validation accuracy: 53.12%, valid loss: 1.4456\n",
      "Epoch: 86, train accuracy: 100.00%, train loss: 0.0038 | Epoch: 86, validation accuracy: 67.19%, valid loss: 1.2532\n",
      "Epoch: 87, train accuracy: 100.00%, train loss: 0.0039 | Epoch: 87, validation accuracy: 65.62%, valid loss: 1.4597\n",
      "Epoch: 88, train accuracy: 100.00%, train loss: 0.0052 | Epoch: 88, validation accuracy: 67.19%, valid loss: 1.4999\n",
      "Epoch: 89, train accuracy: 100.00%, train loss: 0.0432 | Epoch: 89, validation accuracy: 60.94%, valid loss: 1.4472\n",
      "Epoch: 90, train accuracy: 100.00%, train loss: 0.0036 | Epoch: 90, validation accuracy: 67.19%, valid loss: 1.4453\n",
      "training complete\n"
     ]
    }
   ],
   "source": [
    "model = train_network(usedModel, train_loader, valid_loader, loss_fn, optimiser, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(checkpointName+'.pth.tar')\n",
    "\n",
    "if usedModel == resnet18_model:\n",
    "    savedModel = models.resnet18()\n",
    "else:\n",
    "    savedModel = models.resnet50()\n",
    "\n",
    "num_ftrs = savedModel.fc.in_features\n",
    "savedModel.fc = nn.Linear(num_ftrs, num_object_categories)\n",
    "savedModel.load_state_dict(checkpoint['model'])\n",
    "\n",
    "torch.save(savedModel, checkpointName+'.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
